{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hepmc import *\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "This notebook contains combined plots to highlight the behavior of the Monte Carlo Methods. It uses some of the same plotting routines as are used in the Monte Carlo Intodruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same test functions as used in the introduction\n",
    "\n",
    "# periodic sin in 1 dimension\n",
    "sin_1d = lambda x: np.sin(2*np.pi*x)\n",
    "# periodic sin in any dimension; true integral value is 0\n",
    "sin_nd = lambda *x: np.prod([sin_1d(xi) for xi in x], axis=0)\n",
    "\n",
    "sqrtx_inv = lambda *x: np.sqrt(1/np.prod(x, axis=0))\n",
    "sqrtx_inv_trueval = lambda dim: 2**dim  # true integral value depends on dimension\n",
    "\n",
    "# A more complicated test function\n",
    "tf_a = 16\n",
    "tf_b = 1/.2**2\n",
    "def osc(x):\n",
    "    return x**2*np.cos(tf_a*np.pi*x/.2)**2*tf_b\n",
    "def bound(a, x, b):\n",
    "    return (x>a)*(x<=b)\n",
    "def test_function(x):\n",
    "    return bound(.2, x, .4)*osc(x-.2) + bound(.4, x, .6) + bound(.6, x, .8)*osc(.8-x)\n",
    "test_function_true_value = 2*.0333531 + .2\n",
    "\n",
    "# corresponding channels\n",
    "p1 = lambda x: (bound(0,x,.2)*2 + bound(.2,x,.4)*32 + bound(.4,x,.6)*2 + bound(.6,x,.8)*32 + bound(.8,x,1)*2)/70/.2\n",
    "p2 = lambda x: (bound(0,x,.2)*2 + bound(.2,x,.4)*22 + bound(.4,x,.6)*22 + bound(.6,x,.8)*22 + bound(.8,x,1)*2)/70/.2\n",
    "p3 = lambda x: (bound(.2,x,.4)*((x-.2)/.2)**2 + bound(.6,x,.8)*((.8-x)/.2)**2 + bound(.4,x,.6))/(.2 + .1333333)\n",
    "sampling1 = AcceptRejectSampler(p1, 3).sample\n",
    "sampling2 = AcceptRejectSampler(p2, 2).sample\n",
    "sampling3 = AcceptRejectSampler(p3, 3.5).sample\n",
    "\n",
    "dist1 = Distribution.make(p1, ndim=1, rvs=lambda count: sampling1(count).data)\n",
    "dist2 = Distribution.make(p2, ndim=1, rvs=lambda count: sampling2(count).data)\n",
    "dist3 = Distribution.make(p3, ndim=1, rvs=lambda count: sampling3(count).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the plain Monte Carlo estimates\n",
    "This plot shows the distributions of plain Monte Carlo integration of a square integrable and a not square integrable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors for sine and 1/sqrt(x) in any dimension\n",
    "dim = 2\n",
    "it = 2000  # number of iterations for the histogram\n",
    "bins = 160  # number of bins for the histograms\n",
    "N = 5000   # number of function evaluations\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.tight_layout()\n",
    "plt.subplot(121)\n",
    "plt.title(r\"$Square-integrable$\")\n",
    "chi2_1 = plot_distribution(sin_nd, 0, N=N, iterations=it, method=PlainMC(dim), bins=bins)\n",
    "plt.xlabel(\"estimates $E$\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(r\"Not square-integrable\")\n",
    "chi2_2 = plot_distribution(sqrtx_inv, sqrtx_inv_trueval(dim), N=N, iterations=it, method=PlainMC(dim), bins=bins)\n",
    "plt.xlabel(\"estimates $E$\")\n",
    "plt.show()\n",
    "\n",
    "print(chi2_1, chi2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the deviations of importance sampling\n",
    "The integrand is the same test function as before, the deviations (and predicted standard deviations) are showin in a log-log plot, using the plot_rms method introduced previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepmc.core.sampling import Sample\n",
    "g = densities.Gaussian(1)\n",
    "Sample(data=g.rvs(1000), target=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare importance sampling to the stratified boxing from before\n",
    "plt.figure(figsize=(12,5))\n",
    "ax = plt.subplot2grid((2, 2), (0, 0))\n",
    "plt.title(\"Function\")\n",
    "x = np.linspace(0,1,1000)\n",
    "plt.plot(x,test_function(x))\n",
    "ax.tick_params(labelbottom='off') \n",
    "plt.grid()\n",
    "\n",
    "plt.subplot2grid((2, 2), (1, 0))\n",
    "plt.title(\"Probability distributions\")\n",
    "plt.plot(x, p1(x), label=\"p1\", alpha=.9)\n",
    "plt.plot(x, p2(x), label=\"p2\", alpha=.9)\n",
    "plt.plot(x, p3(x), label=\"p3\", alpha=.9)\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "plt.title(\"Standard deviation scaling\")\n",
    "Ns = np.logspace(np.log10(70), 2*np.log10(70), 30, dtype=np.int)\n",
    "plot_rms(test_function, test_function_true_value, iterations=40, Ns=Ns, \n",
    "         methods=[ImportanceMC(dist1, name=\"p1\"),\n",
    "                  ImportanceMC(dist2, name=\"p2\"),\n",
    "                  ImportanceMC(dist3, name=\"p3\"),\n",
    "                  PlainMC()], plot_fit=True)\n",
    "plt.tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camel = densities.Camel(1)\n",
    "var_fn = lambda x: (camel.pdf(x) - 1)**2\n",
    "var_norm = PlainMC()(var_fn, 200000).integral\n",
    "grad_fn = lambda x: np.abs(camel.pdf_gradient(x).flatten())\n",
    "grad_norm = PlainMC()(grad_fn, 20000).integral\n",
    "c1 = Distribution.make(lambda x: var_fn(x)/var_norm, 1, rvs=lambda n: AcceptRejectSampler(var_fn, 3.5).sample(n).data)\n",
    "c2 = MultiChannel([\n",
    "        densities.Gaussian(1, mu=1/3*.9, cov=.1**2/2),\n",
    "        densities.Gaussian(1, mu=2/3, cov=.1**2/2*1.1**2)])\n",
    "c3 = Distribution.make(lambda x: grad_fn(x)/grad_norm, 1, rvs=lambda n: AcceptRejectSampler(grad_fn, 3.5).sample(n).data)\n",
    "\n",
    "# compare importance sampling to the stratified boxing from before\n",
    "plt.figure(figsize=(12,5))\n",
    "ax = plt.subplot2grid((2, 2), (0, 0))\n",
    "plt.title(\"Integrand\")\n",
    "x = np.linspace(0,1,1000)\n",
    "plt.plot(x,camel(x), label='Camel dist.')\n",
    "ymin, ymax = plt.gca().get_ylim()\n",
    "plt.plot([1/3]*2, [-1, 4], '--', color='C2')\n",
    "plt.plot([2/3]*2, [-1, 4], '--', color='C2', label='centers')\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot2grid((2, 2), (1, 0))\n",
    "plt.title(\"Probability distributions\")\n",
    "plt.plot(x, c1(x), label=r\"$p_{\\mathrm{var}}$\")\n",
    "plt.plot(x, c2(x), label=r\"$p_{\\mathrm{imp}}$\")\n",
    "# plt.plot(x, c3(x), label=\"$p_3$\")\n",
    "ymin, ymax = plt.gca().get_ylim()\n",
    "plt.plot([1/3]*2, [-1, 4], '--', color='C2')\n",
    "plt.plot([2/3]*2, [-1, 4], '--', color='C2')\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "plt.title(\"Standard deviation scaling\")\n",
    "Ns = np.logspace(np.log10(70), 2*np.log10(70), 30, dtype=np.int)\n",
    "plot_rms(camel, 1.0, iterations=50, Ns=Ns, \n",
    "         methods=[ImportanceMC(c1, name=r\"$p_{\\mathrm{var}}$\"),\n",
    "                  ImportanceMC(c2, name=r\"$p_{\\mathrm{imp}}$\"),\n",
    "#                   ImportanceMC(c3, name=\"$p_3$\"),\n",
    "                  PlainMC(name='MC plain')], plot_fit=True)\n",
    "\n",
    "plt.gca().legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout(True, rect=(0, 0, .84, 1))\n",
    "plt.savefig('../samples_analysis/img2/mc_importance_stddev.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camel.pdf_gradient([1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the behavior of the deviatinos of multi-channel Monte Carlo\n",
    "The deviations do not lie on a line in the log-log plot because the prefactor in the scaling is reduced.\n",
    "Only in the limit is the scaling like $\\sqrt{1/N}$ again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use on test_function with the three probability distributions from before\n",
    "channels = MultiChannel([dist1, dist2, dist3])\n",
    "\n",
    "mcmci = MultiChannelMC(channels).get_interface_ratios(sub_eval_count=100, r1=0, r2=1, r3=0)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.tight_layout()\n",
    "ax2 = plt.subplot(122)\n",
    "channels.plot_pdf(label=\"Initial pdf\")\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "# Ns = np.logspace(1+np.log10(5), 4, 20, dtype=np.int)\n",
    "Ns = np.logspace(2, 5, 40, dtype=np.int)\n",
    "plot_rms(test_function, test_function_true_value, Ns=Ns, iterations=10, \n",
    "               methods=[mcmci, PlainMC()])\n",
    "plt.sca(ax2)\n",
    "channels.plot_pdf(label=\"After $10^5$ evaluations\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"probability density\")\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# use on test_function with the three probability distributions from before\n",
    "channels = MultiChannel([densities.Gaussian(1, mu=center, cov=0.005) for center in np.random.random(15)])\n",
    "target = densities.Camel(1)\n",
    "camel_value = 1.\n",
    "\n",
    "mcmci = MultiChannelMC(channels).get_interface_ratios(sub_eval_count=400, r1=0, r2=1, r3=0)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.tight_layout()\n",
    "ax2 = plt.subplot(122)\n",
    "channels.plot_pdf(label=\"Initial pdf\")\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "# Ns = np.logspace(1+np.log10(5), 4, 20, dtype=np.int)\n",
    "Ns = np.logspace(2, 5, 30, dtype=np.int)\n",
    "plot_rms(target, camel_value, Ns=Ns, iterations=20, \n",
    "               methods=[mcmci, PlainMC()])\n",
    "plt.sca(ax2)\n",
    "channels.plot_pdf(label=\"After $10^5$ evaluations\")\n",
    "plt.plot(np.linspace(0, 1, 1000), target.pdf(np.linspace(0, 1, 1000)), label='integrand')\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "# plt.ylabel(\"probability density\")\n",
    "plt.legend(loc=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../samples_analysis/img2/mc_multi_adapt.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the statistics of a local Markov Chain random walk\n",
    "If the proposal distributino in the Metropolis algorithm is very local, a large autocorrelation is introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: local proposal and uniform pdf metropolis, proposal area 1/5th as large\n",
    "bins = 20\n",
    "delta = .03\n",
    "count = 1000\n",
    "np.random.seed(42)\n",
    "proposal = lambda s: min(max(0, s-delta/2), 1-delta) + np.random.rand()*delta\n",
    "proposal_pdf = lambda x, y: 1/delta\n",
    "proposal_generator = Proposal.make(proposal, 1)\n",
    "gaussian = densities.Gaussian(1, mu=.5, scale=.1)\n",
    "pdf = gaussian.pdf\n",
    "metrop_gauss02 = DefaultMetropolis(1, pdf, proposal=proposal_generator)\n",
    "\n",
    "sample = metrop_gauss02.sample(count, .78)\n",
    "r = sample.data\n",
    "print(util.bin_wise_chi2(sample, bins=bins))\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "# plt.title(\"time series plot\")\n",
    "plt.subplot(131)\n",
    "plt.plot(r)\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"$x_k$\")\n",
    "plt.grid()\n",
    "\n",
    "# plot histogram\n",
    "plt.subplot(132)\n",
    "# plt.title(\"histogram\")\n",
    "plt.hist(r, bins=bins, normed=True, label=\"sample\")\n",
    "x = np.linspace(0, 1, 1000)\n",
    "plt.grid()\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.plot(x, pdf(x), label=\"distribution\")\n",
    "plt.legend()\n",
    "\n",
    "# plot autocorrelation\n",
    "plt.subplot(133)\n",
    "# plt.title(\"autocorrelation\")\n",
    "acor = util.auto_corr(r).flatten()\n",
    "plt.fill_between(np.arange(len(acor)), acor)\n",
    "plt.xlabel(\"lag $k$\")\n",
    "plt.ylabel(r\"autocorrelation $\\hat{\\rho}_k$\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.target = gaussian\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = util.fd_bins(sample)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2s = []\n",
    "chi2ps = []\n",
    "chi2ns = []\n",
    "for bins in range(5, 500):\n",
    "    c, p, n = util.bin_wise_chi2(sample, bins=bins, bin_range=[[0, 1]])\n",
    "    chi2s.append(c)\n",
    "    chi2ns.append(n)\n",
    "    chi2ps.append(p)\n",
    "plt.subplot(121)\n",
    "plt.plot(chi2s, label=r'$\\chi^2$')\n",
    "plt.plot(chi2ns, label='valid bins')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.subplot(122)\n",
    "plt.semilogy(chi2ps)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC3 sampling of a modulated sin^2\n",
    "Two settings of beta illustrate the impact of that parameter on the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 150\n",
    "\n",
    "fn = lambda x: np.sin(2*np.pi*x)**2 * np.sin(10*2*np.pi*x)**2\n",
    "mc3_sampler = mc3.MC3Uniform(fn, MultiChannel([dist1, dist2, dist3]), delta=.01, beta=0.6)\n",
    "# beta = 1: only importance sampling\n",
    "res = mc3_sampler(([], [500]*40, []), 30000).data\n",
    "print(util.binwise_chi2(lambda x: fn(x)/mc3_sampler.integration_sample.integral, res, bins=bins))\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(221)\n",
    "plt.hist(res, normed=True, bins=bins)\n",
    "plt.xlim(0, 1)\n",
    "x = np.linspace(0, 1, 1000)\n",
    "plt.plot(x, fn(x)/mc3_sampler.integration_sample.integral)\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"distribution\")\n",
    "\n",
    "plt.subplot(222)\n",
    "mc3_sampler.channels.plot_pdf(label=\"overall pdf\")\n",
    "plt.plot(x, fn(x)/mc3_sampler.integration_sample.integral, label=\"equilibrium pdf\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.legend()\n",
    "\n",
    "##### sample using more local updates\n",
    "mc3_sampler.beta=0.01\n",
    "res = mc3_sampler.sample(30000).data\n",
    "# beta = 1: only importance sampling\n",
    "print(util.binwise_chi2(lambda x: fn(x)/mc3_sampler.integration_sample.integral, res, bins=bins))\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.hist(res, normed=True, bins=bins)\n",
    "plt.xlim(0, 1)\n",
    "x = np.linspace(0, 1, 1000)\n",
    "plt.plot(x, fn(x)/mc3_sampler.integration_sample.integral)\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"distribution\")\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(res)\n",
    "plt.grid()\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"$x_k$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = densities.Camel(1)\n",
    "local = proposals.Gaussian(1, cov=0.005)\n",
    "sampler = StochasticOptimizeUpdate(target, local, target_rate=0.3, mult=.5, t0=1, kappa=.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.sample(10000, [.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sampler.local_dist.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "plt.figure(figsize=(10, 3))\n",
    "local = proposals.Gaussian(1, cov=0.005)\n",
    "sampler = StochasticOptimizeUpdate(target, local, target_rate=0.3, mult=.5, t0=1, kappa=.85)\n",
    "\n",
    "count = 10000\n",
    "start = [0.4]\n",
    "state = sampler.init_state(start)\n",
    "sampler.init_adapt(state)\n",
    "\n",
    "rate = []\n",
    "cov = []\n",
    "for t in range(count):\n",
    "    state = sampler.next_state(state, t)\n",
    "    rate.append(sampler.accepted/sampler.generated)\n",
    "    cov.append(sampler.local_dist.cov)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(rate, label='acceptance rate')\n",
    "plt.plot(np.sqrt(np.array(cov).flatten()), label='widths')\n",
    "plt.ylim(-.1, 1.1)\n",
    "plt.legend()\n",
    "plt.xlabel('Interation $t$')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "# second\n",
    "local = proposals.Gaussian(1, cov=0.01)\n",
    "sampler = StochasticOptimizeUpdate(target, local, target_rate=0.3, mult=.5, t0=1, kappa=.51)\n",
    "\n",
    "count = 10000\n",
    "start = [0.4]\n",
    "state = sampler.init_state(start)\n",
    "sampler.init_adapt(state)\n",
    "\n",
    "rate = []\n",
    "cov = []\n",
    "for t in range(count):\n",
    "    state = sampler.next_state(state, t)\n",
    "    rate.append(sampler.accepted/sampler.generated)\n",
    "    cov.append(sampler.local_dist.cov)\n",
    "plt.subplot(122)\n",
    "plt.plot(rate, label='acceptance rate')\n",
    "plt.plot(np.sqrt(np.array(cov).flatten()), label='widths')\n",
    "plt.legend()\n",
    "# plt.ylim(-.1, 1.1)\n",
    "plt.xlabel('Interation $t$')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../samples_analysis/img2/mc3adapt.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "target = densities.Camel(2)\n",
    "local = proposals.Gaussian(2, cov=0.005)\n",
    "sampler = StochasticOptimizeUpdate(target, local, target_rate=0.3, mult=.5, t0=1, kappa=.85)\n",
    "\n",
    "count = 10000\n",
    "start = [0.4]*2\n",
    "state = sampler.init_state(start)\n",
    "sampler.init_adapt(state)\n",
    "\n",
    "rate = []\n",
    "cov = []\n",
    "for t in range(count):\n",
    "    state = sampler.next_state(state, t)\n",
    "    rate.append(sampler.accepted/sampler.generated)\n",
    "    cov.append(sampler.local_dist.cov)\n",
    "\n",
    "plt.plot(rate, label='acceptance rate')\n",
    "plt.plot(np.sqrt(np.array(cov)[:, 0, 0]), label='widths_1')\n",
    "plt.plot(np.sqrt(np.array(cov)[:, 1, 1]), label='widths_2')\n",
    "plt.ylim(-.1, 1.1)\n",
    "plt.legend()\n",
    "plt.xlabel('Interation $t$')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = densities.Camel(2)\n",
    "def target_grad(mgrid, steps):\n",
    "    grad = fn.pot_gradient(np.array(mgrid).reshape(2, steps * steps).transpose())\n",
    "    gradx = grad[:, 0].reshape(mgrid[0].shape)\n",
    "    grady = grad[:, 0].reshape(mgrid[0].shape)\n",
    "    return gradx, grady\n",
    "\n",
    "def target_pot(mgrid):\n",
    "    return -np.ma.log(fn(*mgrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "N = 100000 # training\n",
    "node_count = 500\n",
    "\n",
    "basis = surrogate.GaussianBasis(2, (0.001, .5))\n",
    "\n",
    "# training data\n",
    "xvals = np.random.random((N, 2))\n",
    "fvals = fn(*xvals.transpose())\n",
    "\n",
    "# discard where infty\n",
    "log_vals = -np.ma.log(fvals)\n",
    "xvals = xvals[~log_vals.mask]\n",
    "log_vals = log_vals[~log_vals.mask]\n",
    "\n",
    "# train\n",
    "params = basis.extreme_learning_train(xvals, log_vals, node_count)\n",
    "\n",
    "steps = 100\n",
    "x = np.linspace(.0001, .9999, steps)\n",
    "y = np.linspace(.0001, .9999, steps)\n",
    "mgrid = np.meshgrid(x, y)\n",
    "\n",
    "plt.figure(figsize=(17, 3.8))\n",
    "plt.subplot(143)\n",
    "plt.imshow(basis.eval_gradient_split(*params, *mgrid)[:,:,0], extent=(0, 1, 0, 1), origin='lower', vmin=-110, vmax=110)\n",
    "plt.title('surrogate gradient')\n",
    "plt.subplot(141)\n",
    "plt.imshow(basis.eval_split(*params, *mgrid), extent=(0, 1, 0, 1), origin='lower', vmin=-5, vmax=55)\n",
    "plt.title('surrogate potential')\n",
    "plt.subplot(144)\n",
    "plt.imshow(target_grad(mgrid, steps)[0], extent=(0, 1, 0, 1), origin='lower', vmin=-110, vmax=110)\n",
    "plt.title('gradient')\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.subplot(142)\n",
    "plt.imshow(target_pot(mgrid), extent=(0, 1, 0, 1), origin='lower', vmin=-5, vmax=55)\n",
    "plt.title('potential')\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../samples_analysis/img2/surr-qual.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POTENTIAL\n",
    "spot = basis.eval_split(*params, *mgrid)\n",
    "pot = target_pot(mgrid)\n",
    "pot_ms = np.mean((pot - spot)**2)\n",
    "\n",
    "# GRADIENT\n",
    "# surrogate\n",
    "sgrad = basis.eval_gradient_split(*params, *mgrid)\n",
    "sgradx = sgrad[:, :, 0]\n",
    "sgrady = sgrad[:, :, 1]\n",
    "\n",
    "# real\n",
    "gradx, grady = target_grad(mgrid, steps)\n",
    "\n",
    "grad_ms = np.mean((gradx - sgradx)**2) + np.mean((grady - sgrady)**2)\n",
    "\n",
    "np.sqrt(pot_ms), np.sqrt(grad_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 # training\n",
    "node_count = 100\n",
    "\n",
    "basis = surrogate.GaussianBasis(2)\n",
    "\n",
    "# test data\n",
    "steps = 100\n",
    "x = np.linspace(.0001, .9999, steps)\n",
    "y = np.linspace(.0001, .9999, steps)\n",
    "mgrid = np.meshgrid(x, y)\n",
    "\n",
    "def do_eval(N, node_count):\n",
    "    # training data\n",
    "    xvals = np.random.random((N, 2))\n",
    "    fvals = fn(*xvals.transpose())\n",
    "\n",
    "    # discard where infty\n",
    "    log_vals = -np.ma.log(fvals)\n",
    "    xvals = xvals[~log_vals.mask]\n",
    "    log_vals = log_vals[~log_vals.mask]\n",
    "\n",
    "    # train\n",
    "    params = basis.extreme_learning_train(xvals, log_vals, node_count)\n",
    "    \n",
    "    # POTENTIAL\n",
    "    spot = basis.eval_split(*params, *mgrid)\n",
    "    pot = target_pot(mgrid)\n",
    "    pot_ms = np.mean((pot - spot)**2)\n",
    "    \n",
    "    # GRADIENT\n",
    "    # surrogate\n",
    "    sgrad = basis.eval_gradient_split(*params, *mgrid)\n",
    "    sgradx = sgrad[:, :, 0]\n",
    "    sgrady = sgrad[:, :, 1]\n",
    "    \n",
    "    # real\n",
    "    gradx, grady = target_grad(mgrid, steps)\n",
    "    \n",
    "    grad_ms = np.mean((gradx - sgradx)**2) + np.mean((grady - sgrady)**2)\n",
    "    \n",
    "    return pot_ms, grad_ms\n",
    "\n",
    "def pool_interface(pars):\n",
    "    np.random.seed()\n",
    "    return do_eval(*pars)\n",
    "\n",
    "def get_rms(Ns, node_count, repeats):\n",
    "    pot_rms = []\n",
    "    pot_rms_var = []\n",
    "    grad_rms = []\n",
    "    grad_rms_var = []\n",
    "    for N in Ns:\n",
    "        grad_ms = np.empty(repeats)\n",
    "        pot_ms = np.empty(repeats)\n",
    "        with Pool() as pool:\n",
    "            res = pool.map(pool_interface, [(N, node_count)]*repeats)\n",
    "        for i in range(repeats):\n",
    "            pot_ms[i], grad_ms[i] = res[i] #do_eval(N, node_count)\n",
    "        pot_rms.append(np.mean(np.sqrt(pot_ms)))\n",
    "        pot_rms_var.append(np.var(np.sqrt(pot_ms)))   \n",
    "        grad_rms.append(np.mean(np.sqrt(grad_ms)))\n",
    "        grad_rms_var.append(np.var(np.sqrt(grad_ms)))\n",
    "    return pot_rms, grad_rms, pot_rms_var, grad_rms_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns500 = np.arange(250, 2501, 100)\n",
    "nodes500 = get_rms(Ns500, 500, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns100 = Ns500 - 50\n",
    "nodes100 = get_rms(Ns100, 100, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ns200 = np.arange(250, 1501, 100)\n",
    "# nodes200 = get_rms(Ns200, 200, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "plt.errorbar(Ns100, nodes100[0], fmt='x', yerr=nodes100[2], capsize=0, label='100 nodes')\n",
    "# plt.errorbar(Ns200, nodes200[0], fmt='.--', yerr=nodes200[2], capsize=5, label='200 nodes')\n",
    "plt.errorbar(Ns500, nodes500[0], fmt='.', yerr=nodes500[2], capsize=0, label='500 nodes')\n",
    "plt.gca().set_yscale(\"log\", nonposy='clip')\n",
    "plt.grid(which='major')\n",
    "plt.title('potential')\n",
    "plt.ylabel('mean RMS')\n",
    "plt.xlabel('size of training set $t$')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.errorbar(Ns100, nodes100[1], fmt='x', yerr=nodes100[3], capsize=0, label='100 nodes')\n",
    "# plt.errorbar(Ns200, nodes200[1], fmt='.--', yerr=nodes200[3], capsize=5, label='200 nodes')\n",
    "plt.errorbar(Ns500, nodes500[1], fmt='.', yerr=nodes500[3], capsize=0, label='500 nodes')\n",
    "plt.title('gradient')\n",
    "plt.gca().set_yscale(\"log\", nonposy='clip')\n",
    "plt.xlabel('size of training set $t$')\n",
    "plt.ylabel('mean RMS')\n",
    "plt.grid(which='major')\n",
    "\n",
    "plt.savefig('../samples_analysis/img2/surr-quan.pdf')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physical example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PlainMC(8)(densities.ee_qq(100.), 1000).integral\n",
    "sdf = densities.ee_qq(100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.pdf((np.random.rand(8)-1.5)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_cm = 100.\n",
    "mapping = phase_space.RamboOnDiet(e_cm, 2)\n",
    "target = phase_space.MappedDensity(densities.ee_qq(e_cm), mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_sample = PlainMC(2)(target, 100000)\n",
    "int_sample.integral, int_sample.integral_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.norm = int_sample.integral\n",
    "sample = sampler.sample(10000, [.5]*2)\n",
    "target.mean = sample.mean\n",
    "target.variance = sample.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal = densities.RamboOnDiet(2, e_cm)\n",
    "sampler = DefaultMetropolis(2, target)\n",
    "sample = sampler.sample(10000, [.5]*2)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 50\n",
    "nlearn = 1000\n",
    "x = np.linspace(0, 1, 100)\n",
    "y = np.linspace(0, 1, 100)\n",
    "mgrid = np.meshgrid(x, y)\n",
    "\n",
    "xvals = np.random.random((nlearn, 2))\n",
    "fvals = target.pdf(xvals)\n",
    "\n",
    "# surrogate\n",
    "basis = surrogate.extreme_learning.GaussianBasis(2)\n",
    "log_vals = -np.ma.log(fvals)\n",
    "xvals = xvals[~log_vals.mask]\n",
    "log_vals = log_vals[~log_vals.mask]\n",
    "# train\n",
    "params = basis.extreme_learning_train(xvals, log_vals, nodes)\n",
    "\n",
    "# surrogate gradient\n",
    "def surrogate_gradient(xs):\n",
    "    return basis.eval_gradient(*params, xs)\n",
    "target.pot_gradient = surrogate_gradient\n",
    "util.count_calls(target, 'pot_gradient')\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(basis.eval_split(*params, *mgrid))\n",
    "plt.subplot(122)\n",
    "plt.imshow(-np.ma.log(target(*mgrid)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POTENTIAL\n",
    "def target_pot(mgrid):\n",
    "    return -np.ma.log(target(*mgrid))\n",
    "\n",
    "spot = basis.eval_split(*params, *mgrid)\n",
    "pot = target_pot(mgrid)\n",
    "pot_ms = np.mean((pot - spot)**2)\n",
    "\n",
    "np.sqrt(pot_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.0001, .9999, 100)\n",
    "y = np.linspace(0.0001, .9999, 100) \n",
    "mgrid = np.meshgrid(x, y)\n",
    "prob = target(*mgrid)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(prob, origin='lower', vmin=0)\n",
    "plt.colorbar()\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.subplot(132)\n",
    "plot_hmc_traj(target, mass=1., step_size=0.01, steps=40)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../samples_analysis/img2/ee_qq.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom = densities.Gaussian(2, cov=1.0)\n",
    "sampler = hamiltonian.HamiltonianUpdate(target, mom, 40, 0.01)\n",
    "sampler.sample(10000, [.4]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = hamiltonian.StaticSphericalHMC(target, .01, .01, 40, 40)\n",
    "samplehmc = sampler.sample(10000, [0.4]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplehmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = hamiltonian.SphericalNUTS(target, lambda t: t<1000, Emax=100)\n",
    "samplenuts = sampler.sample(10000, [0.4]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplenuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplenuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = hamiltonian.NUTSUpdate(target, densities.Gaussian(2, cov=1.), lambda t: t<1000, Emax=100)\n",
    "samplesimplenuts = sampler.sample(10000, [0.4]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.bin_wise_chi2(samplesimplenuts, [20, 20], int_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.0001, .9999, 100)\n",
    "y = np.linspace(0.0001, .9999, 100) \n",
    "mgrid = np.meshgrid(x, y)\n",
    "prob = target(*mgrid)\n",
    "\n",
    "plt.figure(figsize=(15*.8, 4.5*.8))\n",
    "plt.subplot(131)\n",
    "plt.imshow(prob, origin='lower', vmin=0)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title('Differential cross section')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.subplot(132)\n",
    "plot_hmc_traj(target, mass=1., step_size=0.01, steps=40)\n",
    "plt.tight_layout()\n",
    "\n",
    "bins = [15, 15]\n",
    "\n",
    "ax2 = plt.subplot(133)\n",
    "ax2.set_title('Spherial HMC')\n",
    "counts, xedges, yedges, im = ax2.hist2d(*samplehmc.data.transpose(), bins=bins, normed=True, vmin=0)\n",
    "if target is not None:\n",
    "    extent = (xedges[0], xedges[-1], yedges[0], yedges[-1])\n",
    "    x = np.linspace(extent[0], extent[1], max(bins)*10)\n",
    "    y = np.linspace(extent[2], extent[3], max(bins)*10)\n",
    "    mgrid = np.meshgrid(x, y)\n",
    "#     ax2.contour(x, y, target(*mgrid))\n",
    "plt.colorbar(im, ax=ax2, fraction=0.046, pad=0.04)\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "plt.savefig('../samples_analysis/img2/ee_qq.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = hamiltonian.StaticSphericalHMC(target, .001, .01, 30, 50)\n",
    "sampler.sample(10000, [0.4]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
