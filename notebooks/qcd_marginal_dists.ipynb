{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepmc.core.densities.qcd import ee_qq_ng, export_hepmc\n",
    "from hepmc.core.phase_space.rambo import RamboOnDiet\n",
    "from hepmc.core.densities.sarge import Sarge\n",
    "from hepmc.core.phase_space.mapping import MappedDensity\n",
    "from hepmc.core.markov.metropolis import DefaultMetropolis\n",
    "from hepmc.core.hamiltonian.hmc import HamiltonianUpdate\n",
    "from hepmc.core.integration.importance import ImportanceMC\n",
    "from hepmc import surrogate\n",
    "from hepmc.core.densities.gaussian import Gaussian\n",
    "from hepmc.core.sampling import Sample\n",
    "from hepmc.core.hamiltonian.spherical_hmc import StaticSphericalHMC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeqqg = ee_qq_ng(1, 100., 5., .3)\n",
    "rambo_mapping = RamboOnDiet(100., 3)\n",
    "mapped = MappedDensity(eeqqg, rambo_mapping)\n",
    "sarge = Sarge(2, 3, 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarge_sample, _, _ = ImportanceMC(sarge).integrate(eeqqg, 10000)\n",
    "sarge_sample_df = pd.DataFrame(sarge_sample.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.PairGrid(sarge_sample_df)\n",
    "f = f.map_diag(plt.hist, weights=sarge_sample.weights, bins=10)\n",
    "f = f.map_offdiag(plt.hist2d, weights=sarge_sample.weights, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarge_sample_df = pd.DataFrame(rambo_mapping.map_inverse(sarge_sample.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(sarge_sample_df)\n",
    "g = g.map_diag(plt.hist, weights=sarge_sample.weights, bins=10)\n",
    "g = g.map_offdiag(plt.hist2d, weights=sarge_sample.weights, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = np.random.random((100000, 5))\n",
    "fvals = mapped.pdf(xvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals_df = pd.DataFrame(xvals)\n",
    "zeros_df = pd.DataFrame(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = sns.PairGrid(zeros_df)\n",
    "h = h.map_diag(plt.hist)\n",
    "h = h.map_offdiag(plt.hist2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 300\n",
    "nlearn = 100000\n",
    "\n",
    "xvals = np.random.random((nlearn, 5))\n",
    "fvals = mapped.pdf(xvals)\n",
    "\n",
    "# surrogate\n",
    "basis = surrogate.extreme_learning.GaussianBasis(5)\n",
    "#log_vals = -np.ma.log(fvals)\n",
    "#xvals = xvals[~log_vals.mask]\n",
    "#log_vals = log_vals[~log_vals.mask]\n",
    "# train\n",
    "%time params = basis.extreme_learning_train(xvals, fvals, nodes)\n",
    "\n",
    "# surrogate\n",
    "def surrogate_fn(xs):\n",
    "    return basis.eval(*params, xs)[0]\n",
    "\n",
    "# surrogate gradient\n",
    "def surrogate_gradient(xs):\n",
    "    return basis.eval_gradient(*params, xs)\n",
    "#mapped.pot_gradient = surrogate_gradient\n",
    "#mapped.pdf_gradient = surrogate_gradient\n",
    "\n",
    "def pot_gradient(xs):\n",
    "    pdf = mapped.pdf(xs)\n",
    "    if pdf == 0:\n",
    "        return np.full(5, np.inf)\n",
    "    \n",
    "    return -surrogate_gradient(xs) / pdf\n",
    "\n",
    "mapped.pot_gradient = pot_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_vals = np.array([surrogate_fn(val) for val in xvals_df.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = sns.PairGrid(xvals_df)\n",
    "i = i.map_diag(plt.hist, weights=surrogate_vals, bins=15)\n",
    "i = i.map_offdiag(plt.hist2d, weights=surrogate_vals, bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.random.random(5)\n",
    "#start = rambo_mapping.map_inverse(sarge_sample.data[-1])[0]\n",
    "print('start:', start)\n",
    "print('pdf:', mapped.pdf(start))\n",
    "print('pot:', mapped.pot(start))\n",
    "print('pot_grad:', mapped.pot_gradient(start))\n",
    "sampler = StaticSphericalHMC(mapped, .005, .1, 2, 10)\n",
    "%time hmc_sample = sampler.sample(15000, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_sample = Sample(data=hmc_sample.data[5000:], weights=hmc_sample.weights[5000:])\n",
    "hmc_sample_df = pd.DataFrame(hmc_sample.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = sns.PairGrid(hmc_sample_df)\n",
    "k = k.map_diag(plt.hist, bins=15, weights=hmc_sample.weights)\n",
    "k = k.map_offdiag(plt.hist2d, bins=15, weights=hmc_sample.weights, cmax=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surrogate HMC without spherical augmentation\n",
    "start = np.random.random(5)\n",
    "print('start:', start)\n",
    "print('pot:', mapped.pot(start))\n",
    "\n",
    "sampler = HamiltonianUpdate(mapped, Gaussian(5, 1.), 30, .001)\n",
    "%time hmc_sample = sampler.sample(15000, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_hmc_sample = Sample(data=rambo_mapping.map(hmc_sample.data[5000:]), weights=np.full(10000, 1/10000))\n",
    "export_hepmc(100., mapped_hmc_sample, \"../samples/qcd/2-3/hmc.hepmc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_sample_df = pd.DataFrame(hmc_sample.data[5000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = sns.PairGrid(hmc_sample_df)\n",
    "h = h.map_diag(plt.hist)\n",
    "h = h.map_offdiag(plt.hist2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.random.random(5)\n",
    "sampler = StaticSphericalHMC(mapped, 3., 3., 4, 4)\n",
    "%time spherical_sample = sampler.sample(15000, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spherical_sample_df = pd.DataFrame(spherical_sample.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = sns.PairGrid(spherical_sample_df)\n",
    "i = i.map_diag(plt.hist, weights=spherical_sample.weights)\n",
    "i = i.map_offdiag(plt.hist2d, weights=spherical_sample.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
