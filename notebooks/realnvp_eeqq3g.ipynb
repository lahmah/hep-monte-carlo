{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from hepmc.core.densities.qcd import ee_qq_ng, export_hepmc, import_hepmc\n",
    "from hepmc.core.densities.nice import Nice\n",
    "from hepmc.core.phase_space.rambo import RamboOnDiet\n",
    "from hepmc.core.phase_space.mapping import MappedDensity\n",
    "from hepmc.core.integration.importance import ImportanceMC\n",
    "from hepmc.core.sampling import Sample, AcceptRejectSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the importance distribution used by Sherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sherpa_weighted_sample = import_hepmc('../samples/qcd/2-5/sherpa_weighted.hepmc')\n",
    "sherpa_weighted_sample = Sample(data=rambo_mapping.map_inverse(sherpa_weighted_sample.data), weights=sherpa_weighted_sample.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(sherpa_weighted_sample.data)\n",
    "f = sns.PairGrid(data)\n",
    "f = f.map_diag(plt.hist, bins=15)\n",
    "f = f.map_offdiag(plt.hist2d, bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training sample and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeqq3g = ee_qq_ng(3, 100., 5., .3)\n",
    "rambo_mapping = RamboOnDiet(100., 5)\n",
    "mapped = MappedDensity(eeqq3g, rambo_mapping)\n",
    "training_sample = import_hepmc('../samples/qcd/2-5/training.hepmc')\n",
    "training_sample = Sample(data=rambo_mapping.map_inverse(training_sample.data), weights=training_sample.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(training_sample.data)\n",
    "f = sns.PairGrid(data)\n",
    "f = f.map_diag(plt.hist, bins=15)\n",
    "f = f.map_offdiag(plt.hist2d, bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a NICE network based on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time nice = Nice(training_sample, train_iters=10000, num_bijectors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the learned distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = nice.rvs(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(sample)\n",
    "f = sns.PairGrid(data)\n",
    "f = f.map_diag(plt.hist, bins=15)\n",
    "f = f.map_offdiag(plt.hist2d, bins=15, range=[[0, 1], [0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use importance sampling to determine the maximum weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_sampler = ImportanceMC(mapped, nice)\n",
    "%time nice_sample = importance_sampler.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = nice_sample.weights.max()\n",
    "print('Maximum weight:', bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_eff = nice_sample.weights.mean()/bound\n",
    "print('Expected unweighting efficiency:', exp_eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the weighted sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_sample = Sample(data=rambo_mapping.map(nice_sample.data), weights=nice_sample.weights)\n",
    "export_hepmc(100., mapped_sample, \"../samples/qcd/2-5/realnvp_weighted.hepmc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Acceptance-Rejection method to generate an unweighted sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = AcceptRejectSampler(target=mapped, sampling_dist=nice, bound=bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sampler.sample(100, batch_size=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the unweighted sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_sample = Sample(data=rambo_mapping.map(sample.data), weights=sample.weights)\n",
    "export_hepmc(100., mapped_sample, \"../samples/qcd/2-5/realnvp.hepmc\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
