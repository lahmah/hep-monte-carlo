{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "#tfd = tf.contrib.distributions\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "layers = tf.contrib.layers\n",
    "tf.set_random_seed(0)\n",
    "from hepmc.core.densities.qcd import ee_qq_ng, export_hepmc, import_hepmc\n",
    "from hepmc.core.densities.nice import Nice\n",
    "from hepmc.core.phase_space.rambo import RamboOnDiet\n",
    "from hepmc.core.phase_space.mapping import MappedDensity\n",
    "from hepmc.core.sampling import Sample\n",
    "from hepmc.core.integration.importance import ImportanceMC\n",
    "from hepmc.core.sampling import Sample, AcceptRejectSampler\n",
    "#from hepmc.core.markov.metropolis import DefaultMetropolis\n",
    "#from hepmc.core.proposals import Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeqq2g = ee_qq_ng(2, 100., 5., .3)\n",
    "rambo_mapping = RamboOnDiet(100., 4)\n",
    "mapped = MappedDensity(eeqq2g, rambo_mapping)\n",
    "training_sample = import_hepmc('../samples/qcd/2-4/training.hepmc')\n",
    "training_sample = Sample(data=rambo_mapping.map_inverse(training_sample.data), weights=training_sample.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(training_sample.data)\n",
    "f = sns.PairGrid(data)\n",
    "f = f.map_diag(plt.hist, bins=15)\n",
    "f = f.map_offdiag(plt.hist2d, bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sherpa_weighted_sample = import_hepmc('../samples/qcd/2-4/sherpa_weighted.hepmc')\n",
    "sherpa_weighted_sample = Sample(data=rambo_mapping.map_inverse(sherpa_weighted_sample.data), weights=sherpa_weighted_sample.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(sherpa_weighted_sample.data)\n",
    "f = sns.PairGrid(data)\n",
    "f = f.map_diag(plt.hist, bins=15)\n",
    "f = f.map_offdiag(plt.hist2d, bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time nice = Nice(training_sample, train_iters=2000, num_bijectors=12, hidden_layers=[128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = nice.rvs(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(sample)\n",
    "f = sns.PairGrid(data)\n",
    "f = f.map_diag(plt.hist, bins=15)\n",
    "f = f.map_offdiag(plt.hist2d, bins=15, range=[[0, 1], [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_sampler = ImportanceMC(mapped, nice)\n",
    "%time nice_sample = importance_sampler.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_sample = Sample(data=rambo_mapping.map(nice_sample.data), weights=nice_sample.weights)\n",
    "export_hepmc(100., mapped_sample, \"../samples/qcd/2-4/realnvp.hepmc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = nice_sample.weights.max()\n",
    "print(bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_sample.weights.mean()/bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = AcceptRejectSampler(target=mapped, bound=bound, sampler=importance_sampler, sampling_pdf=nice.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time sample = sampler.sample(10000, expected_efficiency=.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AcceptRejectSampler(object):\n",
    "    \"\"\" Acceptance Rejection method for sampling a given pdf.\n",
    "    \n",
    "    The method uses a known distribution and sampling method to propose\n",
    "    samples which are then accepted with the probability\n",
    "    pdf(x)/(c * sampling_pdf(x)), thus producing the desired distribution. \n",
    "    The resulting sample is unweighted.\n",
    "    \n",
    "    .. todo::\n",
    "        Handle points that lie above the bound.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target, bound: float, \n",
    "            sampler = None, sampling_pdf = None) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        target\n",
    "            Unnormalized desired probability distribution of the sample.\n",
    "        bound\n",
    "            Constant such that pdf(x) <= bound * sampling_pdf(x)\n",
    "            for all x in the range of sampling.\n",
    "        sampler\n",
    "            The sampler which generates the sample. The default is a uniform sampler.\n",
    "        \"\"\"\n",
    "        self.target = target\n",
    "        self.bound = bound\n",
    "        self.ndim = target.ndim\n",
    "\n",
    "        if sampler is None:\n",
    "            sampler = UniformSampler(target)\n",
    "            def sampling_pdf(x):\n",
    "                return np.ones(x.size)\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.sampling_pdf = sampling_pdf\n",
    "\n",
    "    def sample(self, sample_size: int, expected_efficiency: float = 1.) -> None:\n",
    "        x = np.empty((sample_size, self.ndim))\n",
    "\n",
    "        #indices = np.arange(sample_size)\n",
    "        n_todo = sample_size\n",
    "        trials = 0\n",
    "        while n_todo > 0:\n",
    "            print('n_todo:', n_todo)\n",
    "            trials += int(n_todo/expected_efficiency)\n",
    "            sample = self.sampler.sample(int(n_todo/expected_efficiency))\n",
    "            proposal = sample.data\n",
    "            #accept = np.random.rand(indices.size) * self.bound * self.sampling_pdf(proposal) <= self.target.pdf(proposal)\n",
    "            #accept = np.random.rand(indices.size) * self.bound <= sample.weights\n",
    "            #accept = np.random.rand(indices.size) < sample.weights / self.bound\n",
    "            u = np.random.rand(int(n_todo/expected_efficiency))\n",
    "            accept = u < sample.weights / self.bound\n",
    "            n_accept = accept.sum()\n",
    "            if n_accept <= n_todo:\n",
    "                x[sample_size-n_todo:sample_size-n_todo+n_accept] = proposal[accept]\n",
    "            else:\n",
    "                accepted = proposal[accept]\n",
    "                x[sample_size-n_todo:] = accepted[:n_todo]\n",
    "            n_todo -= n_accept\n",
    "            #x[indices[accept]] = proposal[accept]\n",
    "            #indices = indices[np.logical_not(accept)]\n",
    "        print('Unweighting eff.:', sample_size/trials)\n",
    "        return Sample(data=x, target=self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE=tf.float32\n",
    "NP_DTYPE=np.float32\n",
    "USE_BATCHNORM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_bijectors = 5\n",
    "train_iters = 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_sample = Sample(data=rambo_mapping.map(sample.data), weights=sample.weights)\n",
    "export_hepmc(100., mapped_sample, \"../samples/qcd/2-4/realnvp.hepmc\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
